# üß† Entrenamiento de Modelos de IA - Gu√≠a Completa

## üìã Descripci√≥n General

Este documento explica c√≥mo entrenar y gestionar los modelos de inteligencia artificial utilizados en el sistema de an√°lisis de sentencias jur√≠dicas. Los modelos se almacenan como archivos `.pkl` (pickle) y utilizan t√©cnicas de machine learning para clasificar documentos legales como favorables o desfavorables.

## üèóÔ∏è Arquitectura de Modelos

### üìÅ Estructura de Archivos

```
models/
‚îú‚îÄ‚îÄ modelo_legal.pkl          # Modelo TF-IDF + Logistic Regression
‚îú‚îÄ‚îÄ modelo_legal_sbert.pkl    # Modelo Sentence-BERT + Clasificador
‚îú‚îÄ‚îÄ labels.json              # Etiquetas manuales (opcional)
‚îú‚îÄ‚îÄ frases_clave.json        # Configuraci√≥n de frases clave
‚îî‚îÄ‚îÄ README.md               # Documentaci√≥n b√°sica
```

### üîß Tipos de Modelos

#### 1. **Modelo TF-IDF (`modelo_legal.pkl`)**

**üéØ Tecnolog√≠a:**
- **Vectorizador**: TF-IDF (Term Frequency-Inverse Document Frequency)
- **Clasificador**: Logistic Regression
- **Entrada**: Texto plano
- **Salida**: 0 (desfavorable) o 1 (favorable)

**üìä Estructura del archivo:**
```python
{
    'modelo': 'scikit-learn',
    'vectorizador': TfidfVectorizer,
    'clasificador': LogisticRegression
}
```

**‚úÖ Ventajas:**
- R√°pido de entrenar y ejecutar
- Funciona bien con textos jur√≠dicos
- Requiere menos recursos computacionales
- Interpretable y explicable

#### 2. **Modelo SBERT (`modelo_legal_sbert.pkl`)**

**üéØ Tecnolog√≠a:**
- **Encoder**: Sentence-Transformers (`all-MiniLM-L6-v2`)
- **Clasificador**: Logistic Regression
- **Entrada**: Embeddings sem√°nticos
- **Salida**: 0 (desfavorable) o 1 (favorable)

**üìä Estructura del archivo:**
```python
{
    'encoder_name': 'all-MiniLM-L6-v2',
    'clasificador': LogisticRegression
}
```

**‚úÖ Ventajas:**
- Comprensi√≥n sem√°ntica avanzada
- Mejor rendimiento con textos complejos
- Captura relaciones contextuales
- M√°s preciso en casos ambiguos

## üöÄ Proceso de Entrenamiento

### üìù Preparaci√≥n de Datos

#### 1. **Directorio de Documentos**

El sistema busca documentos en:
- `sentencias/` - Documentos de ejemplo y casos de referencia
- `uploads/` - Documentos subidos por usuarios

#### 2. **Formatos Soportados**

- **PDF**: Procesado con PyPDF2
- **TXT**: Texto plano
- **DOCX**: Procesamiento b√°sico

#### 3. **Requisitos de Calidad**

- **Longitud m√≠nima**: 50 caracteres
- **Encoding**: UTF-8, Latin-1, CP1252
- **Calidad**: Texto bien estructurado y legible

### üè∑Ô∏è Sistema de Etiquetado

#### 1. **Etiquetado Manual (Recomendado)**

Crear archivo `models/labels.json`:
```json
{
  "documento1.pdf": 1,
  "documento2.pdf": 0,
  "documento3.pdf": 1,
  "sentencia_favorable_2024.pdf": 1,
  "resolucion_desfavorable.pdf": 0
}
```

**Valores:**
- `1` = Favorable (procedente, estimado, concedido)
- `0` = Desfavorable (desestimado, rechazado, denegado)

#### 2. **Etiquetado D√©bil Autom√°tico**

Si no hay etiquetas manuales, el sistema usa palabras clave:

**‚úÖ Palabras Positivas (Favorable):**
```python
PALABRAS_POSITIVAS = [
    "procedente",
    "estimamos",
    "estimamos procedente",
    "accedemos",
    "concedemos",
    "reconocemos",
    "favorable",
    "fundada"
]
```

**‚ùå Palabras Negativas (Desfavorable):**
```python
PALABRAS_NEGATIVAS = [
    "desestimamos",
    "infundada",
    "rechazamos",
    "denegamos",
    "desfavorable",
    "no procedente"
]
```

### üîß Comandos de Entrenamiento

#### 1. **Entrenamiento B√°sico**

```bash
# Entrenar modelo TF-IDF
python src/backend/train_model.py

# Entrenar modelo SBERT
python src/backend/train_embeddings.py
```

#### 2. **Entrenamiento con Etiquetas**

```bash
# 1. Crear archivo de etiquetas
echo '{"documento1.pdf": 1, "documento2.pdf": 0}' > models/labels.json

# 2. Ejecutar entrenamiento
python src/backend/train_model.py
python src/backend/train_embeddings.py
```

#### 3. **Entrenamiento Program√°tico**

```python
from pathlib import Path
from src.backend.train_model import train_and_save
from src.backend.train_embeddings import train_and_save as train_sbert

# Configurar directorios
BASE_DIR = Path("sentencias")
UPLOADS_DIR = Path("uploads")
MODELS_DIR = Path("models")
LABELS = MODELS_DIR / "labels.json"

# Entrenar modelo TF-IDF
result_tfidf = train_and_save(BASE_DIR, UPLOADS_DIR, MODELS_DIR, LABELS)
print(f"Modelo TF-IDF: {result_tfidf}")

# Entrenar modelo SBERT
result_sbert = train_sbert(BASE_DIR, UPLOADS_DIR, MODELS_DIR, LABELS)
print(f"Modelo SBERT: {result_sbert}")
```

## üìä Proceso T√©cnico Detallado

### üî§ Vectorizaci√≥n TF-IDF

```python
vectorizer = TfidfVectorizer(
    ngram_range=(1, 2),  # Unigramas y bigramas
    min_df=1,            # Frecuencia m√≠nima de t√©rminos
    max_df=0.95         # Frecuencia m√°xima (elimina muy comunes)
)
```

**Par√°metros explicados:**
- `ngram_range=(1, 2)`: Captura palabras individuales y pares de palabras
- `min_df=1`: Incluye t√©rminos que aparecen al menos una vez
- `max_df=0.95`: Excluye t√©rminos que aparecen en m√°s del 95% de documentos

### üß† Vectorizaci√≥n SBERT

```python
encoder = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = encoder.encode(
    texts, 
    batch_size=16, 
    show_progress_bar=False, 
    normalize_embeddings=True
)
```

**Par√°metros explicados:**
- `all-MiniLM-L6-v2`: Modelo pre-entrenado optimizado para espa√±ol
- `batch_size=16`: Procesa 16 documentos por lote
- `normalize_embeddings=True`: Normaliza vectores para mejor rendimiento

### üìà Entrenamiento del Clasificador

```python
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train, y_train)
```

**Validaci√≥n autom√°tica:**
- Split 80/20 (entrenamiento/test)
- Estratificaci√≥n por clases
- Reporte de clasificaci√≥n autom√°tico

## üéØ Evaluaci√≥n y M√©tricas

### üìä M√©tricas de Calidad

**üéØ Objetivos de rendimiento:**
- **Precisi√≥n**: > 80%
- **Recall**: > 75%
- **F1-Score**: > 0.8
- **Tiempo de respuesta**: < 1 segundo

### üìà Reporte de Clasificaci√≥n

El sistema genera autom√°ticamente un reporte como:

```
              precision    recall  f1-score   support

           0       0.85      0.78      0.81        18
           1       0.82      0.88      0.85        17

    accuracy                           0.83        35
   macro avg       0.83      0.83      0.83        35
weighted avg       0.83      0.83      0.83        35
```

### üß™ Testing del Modelo

```python
import pickle

# Cargar modelo
with open('models/modelo_legal.pkl', 'rb') as f:
    modelo = pickle.load(f)

# Probar predicci√≥n
texto_prueba = "Estimamos procedente la reclamaci√≥n..."
vector = modelo['vectorizador'].transform([texto_prueba])
prediccion = modelo['clasificador'].predict(vector)
probabilidad = modelo['clasificador'].predict_proba(vector)

print(f"Predicci√≥n: {prediccion[0]}")  # 0 o 1
print(f"Probabilidad: {probabilidad[0]}")  # [prob_desfavorable, prob_favorable]
```

## üîÑ Sistema de Fallback

### üõ°Ô∏è Estrategia de Respaldo

Si los modelos no est√°n disponibles, el sistema usa autom√°ticamente:

1. **An√°lisis basado en reglas**
2. **Patrones de frases clave**
3. **Predicci√≥n por palabras clave**
4. **Extracci√≥n de argumentos legales**

### üîß Implementaci√≥n del Fallback

```python
def _cargar_modelo(self):
    """Carga el modelo con fallback autom√°tico"""
    try:
        # Intentar cargar modelo TF-IDF
        with open(self.modelo_path, 'rb') as f:
            modelo_data = pickle.load(f)
            self.modelo = modelo_data.get('modelo')
            self.vectorizador = modelo_data.get('vectorizador')
            self.clasificador = modelo_data.get('clasificador')
    except Exception as e:
        logger.warning(f"Error cargando modelo: {e}")
        # Usar an√°lisis basado en reglas
        self._crear_modelo_basico()
```

## üöÄ Mejores Pr√°cticas

### üìö Preparaci√≥n de Datos

1. **Cantidad**: M√≠nimo 20-30 documentos por clase
2. **Balance**: Mismo n√∫mero de casos favorables/desfavorables
3. **Calidad**: Documentos bien estructurados y legibles
4. **Diversidad**: Variedad de tipos de casos y tribunales

### üè∑Ô∏è Etiquetado

1. **Precisi√≥n**: Revisar manualmente las etiquetas autom√°ticas
2. **Consistencia**: Usar criterios uniformes de clasificaci√≥n
3. **Actualizaci√≥n**: Mantener etiquetas actualizadas
4. **Validaci√≥n**: Verificar etiquetas con expertos jur√≠dicos

### üîÑ Reentrenamiento

1. **Frecuencia**: Reentrenar con nuevos documentos
2. **Monitoreo**: Evaluar rendimiento en producci√≥n
3. **Versionado**: Mantener versiones anteriores de modelos
4. **Testing**: Probar nuevos modelos antes de desplegar

### üõ°Ô∏è Seguridad y Privacidad

1. **Anonimizaci√≥n**: Eliminar datos personales antes del entrenamiento
2. **Control de acceso**: Limitar acceso a modelos entrenados
3. **Auditor√≠a**: Registrar cambios en modelos
4. **Backup**: Mantener copias de seguridad de modelos

## üìã Checklist de Entrenamiento

### ‚úÖ Antes del Entrenamiento

- [ ] Documentos anonimizados y sin datos sensibles
- [ ] Etiquetas manuales creadas y verificadas
- [ ] Balance de clases (favorable/desfavorable)
- [ ] Documentos de calidad suficiente (>50 caracteres)
- [ ] Directorios `sentencias/` y `uploads/` configurados

### ‚úÖ Durante el Entrenamiento

- [ ] Ejecutar ambos scripts de entrenamiento
- [ ] Verificar m√©tricas de rendimiento
- [ ] Revisar reportes de clasificaci√≥n
- [ ] Probar modelos con casos de ejemplo
- [ ] Validar tiempo de respuesta

### ‚úÖ Despu√©s del Entrenamiento

- [ ] Verificar archivos `.pkl` generados
- [ ] Probar predicciones en casos nuevos
- [ ] Documentar cambios en modelos
- [ ] Hacer backup de modelos anteriores
- [ ] Actualizar documentaci√≥n

## üö® Soluci√≥n de Problemas

### ‚ùå Problemas Comunes

#### 1. **Error: "No hay documentos suficientes"**

**Causa**: Menos de 2 documentos en directorios
**Soluci√≥n**: Agregar m√°s documentos o verificar rutas

#### 2. **Error: "Todas las etiquetas son iguales"**

**Causa**: Solo casos favorables o desfavorables
**Soluci√≥n**: Agregar casos del otro tipo o revisar etiquetado

#### 3. **Error: "Modelo muy peque√±o"**

**Causa**: Modelo SBERT incompleto o corrupto
**Soluci√≥n**: Reentrenar modelo SBERT

#### 4. **Bajo rendimiento del modelo**

**Causas posibles**:
- Pocos datos de entrenamiento
- Etiquetas incorrectas
- Documentos de baja calidad
- Desbalance de clases

**Soluciones**:
- Aumentar datos de entrenamiento
- Revisar y corregir etiquetas
- Mejorar calidad de documentos
- Balancear clases

### üîß Comandos de Diagn√≥stico

```bash
# Verificar documentos disponibles
ls -la sentencias/ uploads/

# Verificar etiquetas
cat models/labels.json

# Probar carga de modelo
python -c "
import pickle
with open('models/modelo_legal.pkl', 'rb') as f:
    modelo = pickle.load(f)
print('Modelo cargado correctamente')
print(f'Componentes: {list(modelo.keys())}')
"
```

## üìö Recursos Adicionales

### üîó Documentaci√≥n Relacionada

- [üìã An√°lisis de Discrepancias](ANALISIS_DISCREPANCIAS.md)
- [‚öñÔ∏è Configuraci√≥n de Ponderaci√≥n](CONFIGURACION_PONDERACION.md)
- [üîÆ An√°lisis Predictivo](ANALISIS_PREDICTIVO.md)
- [üìù Generaci√≥n de Demandas](GENERACION_DEMANDAS.md)

### üõ†Ô∏è Herramientas Recomendadas

- **Jupyter Notebook**: Para experimentaci√≥n interactiva
- **scikit-learn**: Documentaci√≥n oficial
- **Sentence-Transformers**: Documentaci√≥n y ejemplos
- **PyPDF2**: Para procesamiento de PDFs

### üìñ Referencias T√©cnicas

- [TF-IDF en scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)
- [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
- [Sentence-Transformers](https://www.sbert.net/)
- [Pickle en Python](https://docs.python.org/3/library/pickle.html)

---

**√öltima actualizaci√≥n**: Enero 2025  
**Versi√≥n**: 2.0.0  
**Autor**: Sistema de An√°lisis Legal IPP/INSS
